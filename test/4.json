{"code": 100, "data": [{"box": [[264, 1], [1137, 1], [1137, 20], [264, 20]], "score": 0.9558882827628149, "text": "This article has been accepted for publication in IEEE Intemet of Things Journal. This is the author's version which has not been fully edited and"}, {"box": [[1662, 1], [2536, 1], [2536, 20], [1662, 20]], "score": 0.9277865690727757, "text": "This article has been accepted for publication in IEEE Intemet of Things Journal. This is the author's version which has not been fully edited and"}, {"box": [[422, 24], [1030, 24], [1030, 44], [422, 44]], "score": 0.9179073024769219, "text": "content may change prior to final publication. Citation information: DOl 10.1109/JIOT.2023.3309992"}, {"box": [[1819, 24], [2427, 24], [2427, 44], [1819, 44]], "score": 0.9179073024769219, "text": "content may change prior to final publication. Citation information: DOl 10.1109/JIOT.2023.3309992"}, {"box": [[2670, 60], [2686, 60], [2686, 80], [2670, 80]], "score": 0.9990444779396057, "text": "2"}, {"box": [[1274, 62], [1287, 62], [1287, 78], [1274, 78]], "score": 0.8057118058204651, "text": "1"}, {"box": [[110, 60], [583, 60], [583, 80], [110, 80]], "score": 0.9118173537509782, "text": "JOURNAL OF LTEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021"}, {"box": [[1507, 60], [1979, 60], [1979, 80], [1507, 80]], "score": 0.9149763690573829, "text": "JOURNAL OF LTEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021"}, {"box": [[1506, 133], [2087, 132], [2087, 156], [1506, 157]], "score": 0.9250543675115032, "text": "repetition: each client adjusts the labels such that any label"}, {"box": [[2103, 132], [2681, 132], [2681, 156], [2103, 156]], "score": 0.9145859400431315, "text": "adding noise to the gradients. Although DP is widely used in"}, {"box": [[163, 139], [1232, 139], [1232, 186], [163, 186]], "score": 0.9501950105895167, "text": "Labels are Culprits: Defending Gradient Attack"}, {"box": [[1506, 160], [2088, 157], [2088, 183], [1506, 186]], "score": 0.9525652440694662, "text": "appears at least twice in a batch, that is, to increase the label"}, {"box": [[2103, 159], [2684, 160], [2684, 184], [2103, 183]], "score": 0.9688972512880961, "text": "FL, to achieve a considerable defensive effect, DP may cause"}, {"box": [[1505, 186], [2087, 185], [2087, 211], [1505, 212]], "score": 0.9472385020025315, "text": "repetition rate in a batch. This operation effectively reduces"}, {"box": [[2105, 187], [2682, 187], [2682, 210], [2105, 210]], "score": 0.9432629933432927, "text": "an intolerable reduction in the test accuracy of the model [11]"}, {"box": [[571, 201], [820, 210], [818, 254], [570, 245]], "score": 0.9543268561363221, "text": "On Privacy"}, {"box": [[1506, 214], [2083, 215], [2083, 238], [1506, 237]], "score": 0.9406228240520235, "text": "the rank of the coefficient matrix and increases the difficulty"}, {"box": [[2106, 215], [2683, 215], [2683, 238], [2106, 238]], "score": 0.9490719636281332, "text": "[25] [26], making it difficult to adjust the noise intensity in"}, {"box": [[1508, 243], [2083, 243], [2083, 264], [1508, 264]], "score": 0.9318173170089722, "text": "of accurately reconstructing the input samples. This work is"}, {"box": [[2106, 242], [2684, 242], [2684, 266], [2106, 266]], "score": 0.9256637245416641, "text": "FL. Unlike the defense approach of DP, our approach does not"}, {"box": [[1507, 269], [2084, 269], [2084, 292], [1507, 292]], "score": 0.9493650662696967, "text": "different from the end-to-end gradient inversion (E2EGI) of"}, {"box": [[2105, 270], [2681, 270], [2681, 293], [2105, 293]], "score": 0.967788390815258, "text": "perturb the uploaded gradients, and it defends against attack by"}, {"box": [[339, 276], [1030, 276], [1030, 302], [339, 302]], "score": 0.9390215641361171, "text": "Zhaohua Li, Le Wang*, Zhaoquan Gu, Yang Lv and Zhihong Tian"}, {"box": [[1507, 297], [2084, 297], [2084, 320], [1507, 320]], "score": 0.9273907161149822, "text": "Li et al. [10], which only improves the accuracy of the label"}, {"box": [[2105, 296], [2682, 295], [2682, 321], [2105, 322]], "score": 0.9511355627929011, "text": "introducing special operations on labels of the input samples."}, {"box": [[1505, 323], [2084, 324], [2084, 347], [1505, 346]], "score": 0.9434527014532397, "text": "reconstruction in scenarios with a high label repetition rate;"}, {"box": [[2131, 324], [2682, 324], [2682, 347], [2131, 347]], "score": 0.8817749365612313, "text": "Rank Analysis By analyzing the analytical form of GAs,"}, {"box": [[1507, 352], [2084, 352], [2084, 375], [1507, 375]], "score": 0.9396061012521386, "text": "however, the reconstruction ability of target sample features in"}, {"box": [[2108, 353], [2682, 353], [2682, 373], [2108, 373]], "score": 0.9187161674102148, "text": "Qian et al. [27] found the smallest model structure that can"}, {"box": [[1507, 378], [2086, 378], [2086, 401], [1507, 401]], "score": 0.9435915976274208, "text": "this scenario has not been verified (E2EGI only uses ImageNet"}, {"box": [[2105, 380], [2682, 378], [2682, 401], [2106, 403]], "score": 0.9217350316249718, "text": "completely reconstruct the input data. Zhu et al. [15] con-"}, {"box": [[732, 404], [1286, 405], [1286, 428], [732, 427]], "score": 0.945808488433644, "text": "However, a class of privacy attacks called gradient attacks"}, {"box": [[134, 407], [686, 407], [686, 427], [134, 427]], "score": 0.9377856123245368, "text": "AbstractFederated learning (FL) is widely studied for local"}, {"box": [[1508, 406], [2083, 406], [2083, 429], [1508, 429]], "score": 0.9403859172016382, "text": "[20], a dataset with a low label repetition rate, to confirm the"}, {"box": [[2104, 405], [2684, 405], [2684, 431], [2104, 431]], "score": 0.9278532903073198, "text": " structed a more comprehensive closed-form of GAs, proposed"}, {"box": [[110, 428], [689, 428], [689, 452], [110, 452]], "score": 0.9448858830663893, "text": "privacy protection, and it involves exchanging model parameters"}, {"box": [[711, 433], [1286, 433], [1286, 457], [711, 457]], "score": 0.9358634998401006, "text": "(GAs) has emerged, such as gradient inversion attacks (GIAs)"}, {"box": [[1507, 433], [2082, 433], [2082, 457], [1507, 457]], "score": 0.9500897755225499, "text": "reconstruction ability). Our analyses and experiments verify"}, {"box": [[2105, 434], [2683, 434], [2683, 455], [2105, 455]], "score": 0.9416683986783028, "text": "a RA index (RA-i) to estimate the difficulty of GAs, and"}, {"box": [[110, 453], [688, 453], [688, 476], [110, 476]], "score": 0.9391386821621754, "text": "rather than raw data among clients. However, gradient attacks"}, {"box": [[1505, 458], [2087, 459], [2087, 485], [1505, 484]], "score": 0.9472685908117602, "text": "that it is difficult for the powerful GAs E2EGI to reconstruct"}, {"box": [[713, 461], [1286, 461], [1286, 484], [713, 484]], "score": 0.9317963918050131, "text": "[7] [8] [9] [10] [11] [12] and closed-form-based attacks (CFAs)"}, {"box": [[2107, 462], [2684, 462], [2684, 482], [2107, 482]], "score": 0.9146460503862616, "text": "advocated the use of the index to design model structures"}, {"box": [[111, 475], [687, 475], [687, 498], [111, 498]], "score": 0.9683058125073792, "text": "(GAs) make a malicious client or parameter server of FL infer"}, {"box": [[1505, 487], [2087, 485], [2087, 511], [1505, 513]], "score": 0.9112478093854313, "text": "target samples with high label repetition rates. (2) Label"}, {"box": [[710, 487], [1287, 488], [1287, 511], [710, 510]], "score": 0.9571079813517057, "text": "[13] [14] [15]. In these attacks, a malicious client or parameter"}, {"box": [[2104, 488], [2683, 487], [2683, 511], [2104, 512]], "score": 0.9083562258814202, "text": "that meet privacy requirements. However, the structure of the"}, {"box": [[110, 497], [686, 498], [686, 518], [110, 517]], "score": 0.9494989171172633, "text": "the local data of other clients only based on the model parameters"}, {"box": [[709, 515], [1287, 515], [1287, 538], [709, 538]], "score": 0.9459045744333111, "text": "server reconstructs the input samples from the gradients. GAs"}, {"box": [[1508, 515], [2084, 515], [2084, 538], [1508, 538]], "score": 0.9485034414979278, "text": "ordering: each client uses the gradient partition calculation"}, {"box": [[2104, 514], [2649, 515], [2649, 539], [2104, 538]], "score": 0.9736323305245104, "text": "model cannot be changed arbitrarily in the training stage."}, {"box": [[110, 521], [686, 521], [686, 541], [110, 541]], "score": 0.8796914374006206, "text": "exchanged. In FL frameworks and processes, it is important"}, {"box": [[709, 541], [1288, 541], [1288, 568], [709, 568]], "score": 0.9317920621364347, "text": "pose a greater challenge to the privacy preservation mechanism"}, {"box": [[1508, 542], [2083, 542], [2083, 566], [1508, 566]], "score": 0.9140971630811692, "text": "(GPC) we introduce to make the gradients depend on the order"}, {"box": [[110, 544], [685, 544], [685, 565], [110, 565]], "score": 0.9530302618370682, "text": "to understand the features that provide heuristic information"}, {"box": [[2130, 543], [2683, 543], [2683, 567], [2130, 567]], "score": 0.8990935583909353, "text": "Larger Batch Size Previous work [7] [8] [9] has demon-"}, {"box": [[110, 567], [686, 567], [686, 587], [110, 587]], "score": 0.9217356370120752, "text": "for inferring raw data, as well as how best to defend against"}, {"box": [[709, 568], [1286, 569], [1286, 592], [709, 591]], "score": 0.9269624791647258, "text": "of FL. In related work, GAs have been improved for use in"}, {"box": [[1508, 571], [2083, 571], [2083, 591], [1508, 591]], "score": 0.9389751265446346, "text": "of the label. The success of GAs is dependent on whether the"}, {"box": [[2107, 572], [2682, 572], [2682, 592], [2107, 592]], "score": 0.9325600324138519, "text": "strated that increasing the batch size can defend against GAs,"}, {"box": [[110, 588], [685, 589], [685, 610], [110, 609]], "score": 0.9433055964566893, "text": "GAs. The academic community is currently investigating this"}, {"box": [[1506, 595], [2084, 594], [2084, 620], [1506, 621]], "score": 0.9579043542185137, "text": "malicious party can \u201cguess\"' the exact order of the labels. We"}, {"box": [[710, 598], [1286, 598], [1286, 618], [710, 618]], "score": 0.9434048642714818, "text": "more complex and deeper models [8] [9] [10], even in various"}, {"box": [[2105, 596], [2682, 597], [2682, 620], [2105, 619]], "score": 0.9251424054945668, "text": "but the defense effect is directly related to the input scale,"}, {"box": [[109, 611], [687, 610], [687, 633], [109, 634]], "score": 0.9410059253374735, "text": "problem. In this study, we demonstrate that the labels of input"}, {"box": [[711, 624], [975, 624], [975, 647], [711, 647]], "score": 0.9443065694400242, "text": "mission scenarios [16] [17]."}, {"box": [[1507, 623], [2083, 623], [2083, 646], [1507, 646]], "score": 0.9530713452446845, "text": "show that the price paid for this \u201cguess' is unacceptable. Our"}, {"box": [[2107, 624], [2682, 624], [2682, 647], [2107, 647]], "score": 0.9529255381945906, "text": "gradient scale, and prior knowledge obtained by attackers."}, {"box": [[108, 634], [687, 632], [687, 656], [108, 658]], "score": 0.9255046414547279, "text": "samples play a key role in the success of GAs. We analyze the"}, {"box": [[734, 651], [1286, 651], [1286, 675], [734, 675]], "score": 0.9412469974270573, "text": "Current mainstream defense approaches are of four main"}, {"box": [[1507, 652], [2084, 649], [2084, 674], [1507, 676]], "score": 0.9555162270863851, "text": "approach can not only defend against GAs but also has little"}, {"box": [[2106, 653], [2683, 653], [2683, 676], [2106, 676]], "score": 0.9351503037173172, "text": "Recent work [10] has shown that despite using a batch size"}, {"box": [[110, 658], [686, 658], [686, 678], [110, 678]], "score": 0.9462152510881424, "text": "rank of the coefficient matrix of the non-homogeneous linear"}, {"box": [[708, 678], [1288, 676], [1288, 702], [708, 704]], "score": 0.9534970383558955, "text": "types: (1) Homomorphic encryption [14] is used to defend"}, {"box": [[1508, 680], [2083, 680], [2083, 700], [1508, 700]], "score": 0.9528725733017099, "text": "influence on the accuracy of the model because no noise is"}, {"box": [[2105, 677], [2683, 678], [2683, 704], [2105, 703]], "score": 0.9393159959997449, "text": "of 256 in a large model, many input samples may still be"}, {"box": [[111, 681], [685, 681], [685, 701], [111, 701]], "score": 0.9628081179800487, "text": "equation of gradients and input samples and propose an approach"}, {"box": [[110, 702], [686, 701], [686, 724], [110, 725]], "score": 0.930079632004102, "text": "that performs special operations on the repetition and order"}, {"box": [[708, 703], [1286, 704], [1286, 730], [708, 729]], "score": 0.9284007635156987, "text": "the malicious parameter server by encrypting the gradients."}, {"box": [[1506, 704], [2087, 704], [2087, 730], [1506, 730]], "score": 0.9455131517167676, "text": "added. The effectiveness of our approach was demonstrated"}, {"box": [[2104, 706], [2684, 705], [2684, 729], [2104, 730]], "score": 0.9603448881477606, "text": "compromised by the gradients. In addition, using a batch size"}, {"box": [[109, 725], [689, 725], [689, 748], [109, 748]], "score": 0.96218650508672, "text": "of labels. The approach achieves a better defense effect against"}, {"box": [[709, 731], [1287, 734], [1287, 758], [709, 754]], "score": 0.941053589185079, "text": "However, because GAs can reconstruct samples from changes"}, {"box": [[1506, 731], [1862, 733], [1862, 757], [1506, 754]], "score": 0.9427320376822823, "text": "both theoretically and experimentally."}, {"box": [[2106, 733], [2684, 733], [2684, 757], [2106, 757]], "score": 0.9303240893317051, "text": "that is too large may increase the training burden of clients"}, {"box": [[111, 748], [686, 748], [686, 769], [111, 769]], "score": 0.9145066450039546, "text": "GAs without using a differential privacy (DP) framework. Our"}, {"box": [[707, 758], [1288, 760], [1288, 786], [707, 784]], "score": 0.9304592510064443, "text": "in the parameters of the global model (also known as average"}, {"box": [[1531, 762], [2018, 762], [2018, 782], [1531, 782]], "score": 0.9303466540116531, "text": "The main contributions of this study are as follows:"}, {"box": [[2107, 763], [2556, 763], [2556, 783], [2107, 783]], "score": 0.9298031205932299, "text": "and reduce the training efficiency of the model."}, {"box": [[110, 772], [684, 772], [684, 792], [110, 792]], "score": 0.9160156855077455, "text": "experimental results show that GAs fail (i.e., without leaking any"}, {"box": [[710, 786], [1287, 785], [1287, 811], [710, 812]], "score": 0.945136484503746, "text": "gradients) [18], it is difficult to defend against malicious"}, {"box": [[2131, 789], [2682, 789], [2682, 812], [2131, 812]], "score": 0.9605136775133902, "text": "A defense method for perturbing the features of the input"}, {"box": [[110, 793], [686, 795], [686, 815], [110, 813]], "score": 0.9127934315512257, "text": "valid information about local data) during the entire training"}, {"box": [[1531, 792], [2082, 793], [2082, 817], [1531, 816]], "score": 0.9061431884765625, "text": "1) We proved that the labels of the input samples played a"}, {"box": [[711, 814], [1287, 814], [1287, 837], [711, 837]], "score": 0.9701689452894272, "text": "clients. (2) Differential privacy (DP) [19] implements defense"}, {"box": [[109, 815], [686, 815], [686, 838], [109, 838]], "score": 0.9444534939432901, "text": "process of a deep convolutional network in FL, and the accuracy"}, {"box": [[2107, 816], [2683, 816], [2683, 839], [2107, 839]], "score": 0.9188305422411127, "text": "sample has also been proposed [28] [29]. However, it is yet"}, {"box": [[1560, 820], [1862, 820], [1862, 843], [1560, 843]], "score": 0.945446870019359, "text": "key role in the success of GAs."}, {"box": [[109, 838], [688, 839], [688, 860], [109, 859]], "score": 0.9447732120752335, "text": "of the network is less affected than that of DP. The code is"}, {"box": [[710, 842], [1285, 842], [1285, 866], [710, 866]], "score": 0.9472846650871737, "text": "by adding noise to the gradients. A prominent problem with"}, {"box": [[2106, 842], [2683, 841], [2683, 865], [2106, 866]], "score": 0.9359431984060902, "text": "unclear whether this method is effective in the large model"}, {"box": [[1530, 847], [2083, 847], [2083, 871], [1530, 871]], "score": 0.9159571159969676, "text": "2) We proposed a \u2018label repetition\" operation and theo-"}, {"box": [[110, 863], [667, 863], [667, 883], [110, 883]], "score": 0.9693906903266907, "text": "available at https://github.com/zhaohuali/Label-based-Defense."}, {"box": [[709, 868], [1286, 870], [1286, 893], [709, 891]], "score": 0.9388180466021522, "text": "DP is that it is difficult to adjust the noise intensity in"}, {"box": [[2105, 871], [2684, 871], [2684, 894], [2105, 894]], "score": 0.941144829704648, "text": "training scenario considered in this study. Hence, this type of"}, {"box": [[1560, 874], [2086, 873], [2086, 899], [1560, 900]], "score": 0.9475089223296554, "text": "retically and experimentally showed that it can defend"}, {"box": [[132, 896], [686, 896], [686, 919], [132, 919]], "score": 0.9459890340055738, "text": "Index TermsData Privacy, Federated Learning, Deep Learn-"}, {"box": [[710, 896], [1286, 896], [1286, 919], [710, 919]], "score": 0.9514476821340364, "text": "FL to achieve a better trade-off between privacy and model"}, {"box": [[2106, 897], [2684, 897], [2684, 920], [2106, 920]], "score": 0.9370875810423205, "text": "method falls outside the scope of this study, and more related"}, {"box": [[1563, 903], [1689, 903], [1689, 926], [1563, 926]], "score": 0.9504814694325129, "text": "against GAs."}, {"box": [[110, 920], [483, 920], [483, 940], [110, 940]], "score": 0.9629250660538673, "text": "ing, Gradient Attack, Gradient Inversion"}, {"box": [[710, 925], [1284, 923], [1284, 946], [710, 948]], "score": 0.9199749103614262, "text": "performance. (3) Using rank analysis (RA) [15] to modify"}, {"box": [[2104, 924], [2683, 921], [2683, 948], [2105, 952]], "score": 0.9505725829832016, "text": "papers can be analyzed [30] [31]. As in the case of DP, trade-"}, {"box": [[1530, 929], [2083, 929], [2083, 952], [1530, 952]], "score": 0.9275779465459427, "text": "3) We implemented a \u2018label ordering' operation by in-"}, {"box": [[711, 951], [1287, 951], [1287, 975], [711, 975]], "score": 0.9368211423357328, "text": "the model structure applies only to model design because the"}, {"box": [[2107, 954], [2516, 954], [2516, 974], [2107, 974]], "score": 0.9266731690387336, "text": "offs that are difficult to reconcile still exist."}, {"box": [[1562, 957], [2084, 957], [2084, 980], [1562, 980]], "score": 0.955811559007718, "text": "troducing GPC, which considerably increased the time"}, {"box": [[305, 974], [490, 976], [490, 999], [305, 997]], "score": 0.9750638008117676, "text": "I. INTRODUCTION"}, {"box": [[711, 980], [1285, 980], [1285, 1000], [711, 1000]], "score": 0.9357861522900857, "text": "structure of the model cannot be changed arbitrarily in the"}, {"box": [[2130, 979], [2684, 979], [2684, 1005], [2130, 1005]], "score": 0.9549402085217562, "text": "Unlike in the above defense approach, we found that the"}, {"box": [[1562, 984], [1753, 984], [1753, 1007], [1562, 1007]], "score": 0.9529183854659399, "text": "complexity of GAs."}, {"box": [[709, 1005], [1286, 1004], [1286, 1028], [709, 1029]], "score": 0.9209946449846029, "text": "training stage. (4) Increasing the batch size makes the gradient"}, {"box": [[2107, 1007], [2681, 1007], [2681, 1030], [2107, 1030]], "score": 0.9363934660361986, "text": "success of GAs is dependent on the labels of input samples."}, {"box": [[1531, 1016], [2083, 1016], [2083, 1039], [1531, 1039]], "score": 0.9287591023104531, "text": "Our paper is structured as follows: In Sec.I, we discuss"}, {"box": [[708, 1033], [1287, 1032], [1287, 1056], [708, 1057]], "score": 0.9618299151620557, "text": "containing the input information sparse, and this approach has"}, {"box": [[2106, 1033], [2684, 1033], [2684, 1060], [2106, 1060]], "score": 0.9467422741430777, "text": "Hence, we propose two special operations on the labels"}, {"box": [[155, 1035], [686, 1036], [686, 1061], [155, 1060]], "score": 0.9218208700418472, "text": " data from various parties and ensuring privacy, distributed"}, {"box": [[1508, 1045], [2082, 1045], [2082, 1066], [1508, 1066]], "score": 0.9444072445233663, "text": "related work. In Sec.II, we introduce the threat model that our"}, {"box": [[709, 1061], [1286, 1061], [1286, 1084], [709, 1084]], "score": 0.928322197786018, "text": "a limited effect [10]; additionally, a batch size that is overlarge"}, {"box": [[2105, 1061], [2681, 1061], [2681, 1084], [2105, 1084]], "score": 0.9303790256381035, "text": "to achieve defense. Because we introduce no perturbation"}, {"box": [[109, 1065], [689, 1065], [689, 1088], [109, 1088]], "score": 0.9214117790831894, "text": "and federated learning (FL) [3] [4] [5] [6] has been proposed"}, {"box": [[1507, 1070], [2084, 1070], [2084, 1096], [1507, 1096]], "score": 0.943454134464264, "text": "approach defends against. In Sec.IV, we detail our approach,"}, {"box": [[710, 1087], [1286, 1087], [1286, 1110], [710, 1110]], "score": 0.9498513511946944, "text": "will place an extra burden on both the model construction and"}, {"box": [[2105, 1087], [2683, 1088], [2683, 1114], [2105, 1113]], "score": 0.955801475931097, "text": "and keep the neural network model and training samples"}, {"box": [[110, 1091], [686, 1091], [686, 1114], [110, 1114]], "score": 0.9337279840751931, "text": "and widely adopted. The fundamental mechanism of FL is"}, {"box": [[1507, 1099], [2083, 1097], [2083, 1120], [1507, 1122]], "score": 0.9183306654945749, "text": "providing explanations and justifications for two operations:"}, {"box": [[709, 1113], [814, 1113], [814, 1136], [709, 1136]], "score": 0.9891156752904257, "text": "the clients."}, {"box": [[2105, 1115], [2681, 1116], [2681, 1139], [2105, 1138]], "score": 0.9470686516978524, "text": "unchanged, our method has less impact on the model per-"}, {"box": [[109, 1117], [687, 1116], [687, 1139], [109, 1140]], "score": 0.923719694902157, "text": "that the clients involved in the model construction do not"}, {"box": [[1508, 1125], [2083, 1125], [2083, 1148], [1508, 1148]], "score": 0.9321540056682024, "text": "\"label repetition\" and \u201clabel ordering\" Finally, in Sec.V, we"}, {"box": [[733, 1142], [1284, 1142], [1284, 1166], [733, 1166]], "score": 0.9300346145263085, "text": "These problems require an approach that can not only"}, {"box": [[2106, 1141], [2204, 1145], [2203, 1169], [2105, 1165]], "score": 0.9464661810133193, "text": "formance."}, {"box": [[109, 1146], [687, 1146], [687, 1170], [109, 1170]], "score": 0.9419027537107467, "text": "share their data directly but cooperate in training a global"}, {"box": [[1506, 1151], [2084, 1152], [2084, 1179], [1506, 1178]], "score": 0.9237050814706771, "text": "compare the performance of our approach with that of existing"}, {"box": [[708, 1169], [1288, 1167], [1288, 1193], [708, 1195]], "score": 0.9386777008166078, "text": "provide a good defense effect against GAs but also have fewer"}, {"box": [[109, 1172], [687, 1173], [687, 1196], [109, 1195]], "score": 0.9110470765926799, "text": "model under the coordination of the parameter server. Clients"}, {"box": [[1505, 1178], [2084, 1179], [2084, 1205], [1505, 1204]], "score": 0.957951158285141, "text": "defense approaches and discuss the independent defensive"}, {"box": [[709, 1195], [1284, 1196], [1284, 1219], [709, 1218]], "score": 0.9225109249353409, "text": "side effects on the model training (notably model accuracy)."}, {"box": [[109, 1199], [687, 1200], [687, 1223], [109, 1222]], "score": 0.9483861792832613, "text": "calculate gradients using local data and upload the gradients to"}, {"box": [[2290, 1203], [2500, 1204], [2500, 1227], [2290, 1226]], "score": 0.9467462055823382, "text": "III. THREAT MODEL"}, {"box": [[1505, 1206], [2067, 1205], [2067, 1231], [1505, 1232]], "score": 0.9255778545238933, "text": "effects of each part of our approach in the ablation studies."}, {"box": [[709, 1222], [1285, 1222], [1285, 1245], [709, 1245]], "score": 0.9323751633450136, "text": "The way clients calculate gradients cannot be intervened in"}, {"box": [[109, 1226], [688, 1226], [688, 1252], [109, 1252]], "score": 0.9422570252027668, "text": "the parameter server, which aggregates all gradients from the"}, {"box": [[2130, 1241], [2682, 1241], [2682, 1265], [2130, 1265]], "score": 0.9379875434021796, "text": "In FL, the ultimate goal is to minimize the objective function"}, {"box": [[710, 1251], [1287, 1251], [1287, 1275], [710, 1275]], "score": 0.9277439628328595, "text": "FL. So clients can adjust the training setup according to their"}, {"box": [[108, 1254], [690, 1252], [690, 1279], [108, 1280]], "score": 0.9664361095819317, "text": "clients, updates the global model, and synchronizes the model"}, {"box": [[1695, 1266], [1896, 1268], [1895, 1291], [1695, 1289]], "score": 0.9460670165717602, "text": "II. RELATED WORK"}, {"box": [[2104, 1268], [2146, 1268], [2146, 1295], [2104, 1295]], "score": 0.9171715080738068, "text": "[3],"}, {"box": [[710, 1278], [1286, 1278], [1286, 1301], [710, 1301]], "score": 0.9461808608750165, "text": "privacy protection requirements, but this adjustment cannot"}, {"box": [[108, 1280], [239, 1282], [238, 1306], [108, 1304]], "score": 0.9984950105349223, "text": "to all clients."}, {"box": [[2335, 1289], [2556, 1291], [2556, 1321], [2334, 1319]], "score": 0.9061451491556669, "text": "F(W) = Ei~p[F;(W)],"}, {"box": [[710, 1305], [1286, 1305], [1286, 1328], [710, 1328]], "score": 0.9089930212056195, "text": "have too much impact on the construction of the global"}, {"box": [[1530, 1304], [2084, 1304], [2084, 1327], [1530, 1327]], "score": 0.9429572044678454, "text": "Secure Aggregation This method involves the encrypted"}, {"box": [[2652, 1307], [2686, 1307], [2686, 1336], [2652, 1336]], "score": 0.9994861880938212, "text": "(1)"}, {"box": [[126, 1319], [686, 1320], [686, 1343], [126, 1342]], "score": 0.9474395161325281, "text": "Date of the current version: July 21, 2023. This research was sup-"}, {"box": [[2231, 1324], [2556, 1325], [2556, 1353], [2231, 1351]], "score": 0.8686827520529429, "text": "where F;(W) = E\u03b5~D,[f;(W, $)],"}, {"box": [[710, 1330], [1286, 1332], [1286, 1357], [710, 1354]], "score": 0.965107759491342, "text": "model. Our methods provide clients with a new training setup,"}, {"box": [[1506, 1331], [2083, 1331], [2083, 1358], [1506, 1358]], "score": 0.9573245503134646, "text": "sharing and aggregation of gradients [14] [21], effectively"}, {"box": [[109, 1342], [687, 1341], [687, 1362], [109, 1363]], "score": 0.9527724849827149, "text": "ported in part by Guangdong High-level University Foundation Program"}, {"box": [[1506, 1361], [2083, 1359], [2083, 1382], [1506, 1384]], "score": 0.9139619229132669, "text": "preventing the parameter server from performing GAs. How-"}, {"box": [[712, 1361], [1287, 1361], [1287, 1384], [712, 1384]], "score": 0.9388084776939885, "text": "which reduces the negative impact of defense strategies on the"}, {"box": [[111, 1363], [685, 1363], [685, 1383], [111, 1383]], "score": 0.9509486617410884, "text": "(SL2022A03J00918), the Major Key Project of PCL (PCL2022A03), Guang-"}, {"box": [[2108, 1368], [2682, 1368], [2682, 1391], [2108, 1391]], "score": 0.9362011860918116, "text": "where W denotes the parameter for the global model, Fi"}, {"box": [[110, 1383], [685, 1383], [685, 1403], [110, 1403]], "score": 0.923472715748681, "text": "dong Key R&D Program of China (2019B010136003), Guangdong Post-"}, {"box": [[1506, 1386], [2083, 1388], [2083, 1411], [1506, 1409]], "score": 0.9457178014819905, "text": "ever, malicious clients can obtain non-encrypted parameters"}, {"box": [[711, 1388], [1287, 1388], [1287, 1411], [711, 1411]], "score": 0.9520709350191313, "text": "model test accuracy under the premise of ensuring that the"}, {"box": [[2105, 1394], [2684, 1394], [2684, 1417], [2105, 1417]], "score": 0.9148225158452987, "text": "is the local objective function at client i, and p denotes a"}, {"box": [[112, 1404], [685, 1404], [685, 1424], [112, 1424]], "score": 0.9602230130762294, "text": "graduate Education Innovation Program Project (2019JGXM82), Guangdong"}, {"box": [[712, 1414], [1287, 1414], [1287, 1437], [712, 1437]], "score": 0.9345423077780103, "text": "upload gradient does not leak local data. Building on recursive"}, {"box": [[1507, 1414], [2086, 1414], [2086, 1437], [1507, 1437]], "score": 0.9344152435660362, "text": "of the global model and perform GAs to reconstruct input"}, {"box": [[2106, 1422], [2683, 1422], [2683, 1445], [2106, 1445]], "score": 0.9584310881553157, "text": "distribution of the population of clients. The local objective"}, {"box": [[111, 1424], [685, 1424], [685, 1443], [111, 1443]], "score": 0.9374875615943562, "text": "Higher Education Innovation Group (2020KCXTD007), Guangzhou Higher"}, {"box": [[711, 1441], [1287, 1441], [1287, 1465], [711, 1465]], "score": 0.9260972884663364, "text": "gradient attack on privacy (R-GAP) [15], we show that the"}, {"box": [[1508, 1441], [2084, 1441], [2084, 1465], [1508, 1465]], "score": 0.9391602079073588, "text": "samples from the average gradients (i.e., the changes in the"}, {"box": [[110, 1443], [686, 1443], [686, 1464], [110, 1464]], "score": 0.9455852179384944, "text": "Education Innovation Group (202032854), Guangdong Basic and Applied"}, {"box": [[2104, 1447], [2683, 1448], [2683, 1475], [2104, 1474]], "score": 0.9278513696686975, "text": "function fi(W, s) is often the same across all clients; Di"}, {"box": [[110, 1465], [686, 1465], [686, 1485], [110, 1485]], "score": 0.9344016660505267, "text": "Basic Research Foundation of China (2022A1515011542), and Guangzhou"}, {"box": [[710, 1468], [1289, 1468], [1289, 1494], [710, 1494]], "score": 0.9666604292197306, "text": "labels of the input samples play a key role in the success of"}, {"box": [[1505, 1468], [2084, 1467], [2084, 1493], [1505, 1494]], "score": 0.9427953670101781, "text": "parameters of the global model with adjacent time steps) [18]."}, {"box": [[2105, 1476], [2682, 1477], [2682, 1500], [2105, 1499]], "score": 0.9307634868929463, "text": "denotes the distribution of local data. The objective function"}, {"box": [[110, 1485], [560, 1485], [560, 1505], [110, 1505]], "score": 0.9471420201388272, "text": "Science and technology program of China (202201010606)."}, {"box": [[711, 1496], [1286, 1496], [1286, 1519], [711, 1519]], "score": 0.9313550776448744, "text": "GAs by analyzing the rank of the coefficient matrix of the"}, {"box": [[1506, 1495], [2083, 1496], [2083, 1519], [1506, 1518]], "score": 0.9316197047010064, "text": "It is difficult to prevent the collusion of the clients with the"}, {"box": [[125, 1504], [688, 1502], [688, 1525], [125, 1527]], "score": 0.9392568809645516, "text": "Z. Li is with University of Electronic Science and Technology of China"}, {"box": [[2106, 1504], [2681, 1504], [2681, 1527], [2106, 1527]], "score": 0.9347057867858369, "text": "in (1) can be solved by gradient descent. In time-step t, W"}, {"box": [[1506, 1522], [2084, 1521], [2084, 1548], [1506, 1549]], "score": 0.938532331927878, "text": "parameter server to evade this defense. Moreover, a technique"}, {"box": [[110, 1524], [688, 1525], [688, 1546], [110, 1545]], "score": 0.9408165228863558, "text": "(e-mail: 13250240950@ 163.com); Yang Lv, and Z. Tian are with Cyberspace"}, {"box": [[710, 1525], [1285, 1525], [1285, 1545], [710, 1545]], "score": 0.9288611401591385, "text": "non-homogeneous linear equation about gradients and input"}, {"box": [[2105, 1530], [2378, 1530], [2378, 1557], [2105, 1557]], "score": 0.937492948991281, "text": "can be updated by the form,"}, {"box": [[110, 1547], [687, 1547], [687, 1567], [110, 1567]], "score": 0.9646734959549375, "text": "Institute of Advanced Technology, Guangzhou University, Guangzhou, China"}, {"box": [[1507, 1550], [2082, 1550], [2082, 1574], [1507, 1574]], "score": 0.9494154028973337, "text": "for gradient disaggregation has been proposed, which allows"}, {"box": [[710, 1551], [1287, 1551], [1287, 1575], [710, 1575]], "score": 0.9681482911109924, "text": "samples. Unlike the previous method, our proposed defense"}, {"box": [[109, 1566], [688, 1567], [688, 1587], [109, 1586]], "score": 0.924581519935442, "text": "(e-mail: 2112006172@e.gzhu.edu.cn, tianzhihong@gzhu.edu.cn); Z. Gu is"}, {"box": [[1507, 1578], [2083, 1578], [2083, 1601], [1507, 1601]], "score": 0.9206094038291056, "text": "the parameter server to decompose the client's gradients from"}, {"box": [[711, 1579], [1287, 1579], [1287, 1602], [711, 1602]], "score": 0.9604317659423465, "text": "mainly adjusts the training settings to play the defensive role"}, {"box": [[2195, 1580], [2594, 1584], [2593, 1614], [2195, 1610]], "score": 0.877532639564612, "text": "W(t+1) = W(t) - nvW(t), t = 0, 1, 2,..."}, {"box": [[2651, 1586], [2686, 1586], [2686, 1614], [2651, 1614]], "score": 0.9549100796381632, "text": "(2)"}, {"box": [[109, 1587], [689, 1587], [689, 1610], [109, 1610]], "score": 0.948996887278201, "text": "with School of Computer Science and Technology, Harbin Institute of"}, {"box": [[709, 1604], [1287, 1606], [1287, 1629], [709, 1627]], "score": 0.947965834675164, "text": "of labels for GAs and does not make any additional changes"}, {"box": [[1506, 1604], [2084, 1604], [2084, 1630], [1506, 1630]], "score": 0.9488767981529236, "text": "the average gradient, so as to reconstruct the client's data"}, {"box": [[109, 1607], [686, 1607], [686, 1630], [109, 1630]], "score": 0.9513234005254858, "text": "Technology (Shenzhen) and Peng Cheng Laboratory, Shenzhen, China (e-"}, {"box": [[109, 1629], [315, 1629], [315, 1649], [109, 1649]], "score": 0.8803858115122869, "text": "mail: zqgu@ gzhu.edu.cn) ."}, {"box": [[2106, 1630], [2685, 1628], [2685, 1654], [2107, 1657]], "score": 0.9376784322723266, "text": "where n is the learning rate, and VW(t) denotes the derivative"}, {"box": [[708, 1630], [1285, 1632], [1285, 1657], [708, 1654]], "score": 0.9113950527140072, "text": "to the uploaded gradient and model structure, minimizing"}, {"box": [[1506, 1628], [1682, 1631], [1681, 1658], [1506, 1654]], "score": 0.9338449314236641, "text": "through GAs [22]"}, {"box": [[128, 1648], [686, 1648], [686, 1669], [128, 1669]], "score": 0.9233123413154057, "text": "Corresponding author: L. Wang is with Cyberspace Institute of Advanced"}, {"box": [[1527, 1657], [2088, 1660], [2088, 1686], [1527, 1684]], "score": 0.9326805028048428, "text": "Differential Privacy Differential privacy (DP) for deep"}, {"box": [[710, 1661], [1286, 1661], [1286, 1684], [710, 1684]], "score": 0.9614861715923656, "text": "the side effects of defense on model training. The main"}, {"box": [[2104, 1661], [2684, 1661], [2684, 1684], [2104, 1684]], "score": 0.9410021161591565, "text": "of F(W) with respect to W. Because differentiation and"}, {"box": [[108, 1667], [687, 1668], [687, 1691], [108, 1690]], "score": 0.947767383221424, "text": "Technology, Guangzhou University, Guangzhou, China, and Peng Cheng"}, {"box": [[709, 1686], [1288, 1686], [1288, 1712], [709, 1712]], "score": 0.9304416127372206, "text": "idea of our approach is divided into two parts. (1) Label"}, {"box": [[1505, 1685], [2084, 1687], [2084, 1713], [1505, 1711]], "score": 0.9022246835723756, "text": "learning [19] [23] [24] defends against differential attacks by"}, {"box": [[2104, 1687], [2685, 1687], [2685, 1713], [2104, 1713]], "score": 0.9541800726543773, "text": "expectation can be swapped, the formula for the average"}, {"box": [[108, 1689], [586, 1689], [586, 1712], [108, 1712]], "score": 0.9138930166353945, "text": "Laboratory, Shenzhen, China (e-mail: wanglelemail@ yeah.net)."}, {"box": [[62, 1743], [1327, 1744], [1327, 1765], [62, 1764]], "score": 0.9455618217240932, "text": "Authorized licensed use limited to: University of Electronic Science and Tech of China. Downloaded on September 20,2023 at 12:28:43 UTC from IEEE Xplore. Restrictions apply"}, {"box": [[1460, 1744], [2724, 1744], [2724, 1765], [1460, 1765]], "score": 0.9449067110615659, "text": "Authorized licensed use limited to: University of Electronic Science and Tech of China. Downloaded on September 20,2023 at 12:28:43 UTC from IEEE Xplore. Restrictions apply."}, {"box": [[262, 1762], [1328, 1763], [1328, 1782], [262, 1781]], "score": 0.9260502962363248, "text": "@ 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE pemission. See https:/www.ieee.org/publications/rights/index.html for more infomation."}, {"box": [[1659, 1763], [2726, 1763], [2726, 1782], [1659, 1782]], "score": 0.9290163816724505, "text": "@ 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https:/www.ieee.org/publications/rights/index.html for more information."}]}