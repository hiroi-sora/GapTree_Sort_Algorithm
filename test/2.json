{"code": 100, "data": [{"box": [[270, 49], [720, 49], [720, 68], [270, 68]], "score": 0.917002493639787, "text": "Truc Nguyen, Phung Lai, Khang Tran, NhatHai Phan, My T. Thai"}, {"box": [[655, 99], [674, 99], [674, 115], [655, 115]], "score": 0.997950037320455, "text": "1.0"}, {"box": [[875, 100], [891, 100], [891, 113], [875, 113]], "score": 0.709263801574707, "text": "1.0"}, {"box": [[378, 101], [393, 101], [393, 113], [378, 113]], "score": 0.9996789495150248, "text": "1.0"}, {"box": [[149, 106], [173, 106], [173, 121], [149, 121]], "score": 0.9782633185386658, "text": "Adv"}, {"box": [[708, 106], [730, 106], [730, 121], [708, 121]], "score": 0.8991398811340332, "text": "Ady"}, {"box": [[429, 108], [449, 108], [449, 120], [429, 120]], "score": 0.937670628229777, "text": "Adv"}, {"box": [[875, 119], [892, 119], [892, 138], [875, 138]], "score": 0.9985822041829427, "text": "0.9"}, {"box": [[150, 120], [174, 120], [174, 136], [150, 136]], "score": 0.997286319732666, "text": "TPR"}, {"box": [[430, 120], [452, 120], [452, 136], [430, 136]], "score": 0.9949565331141154, "text": "TPR"}, {"box": [[709, 120], [732, 120], [732, 136], [709, 136]], "score": 0.9967970649401346, "text": "TPR"}, {"box": [[596, 121], [614, 121], [614, 138], [596, 138]], "score": 0.9950100183486938, "text": "0.9"}, {"box": [[150, 134], [174, 134], [174, 150], [150, 150]], "score": 0.9651841521263123, "text": "TNR"}, {"box": [[709, 134], [732, 134], [732, 150], [709, 150]], "score": 0.9942996700604757, "text": "TNR"}, {"box": [[431, 137], [451, 137], [451, 148], [431, 148]], "score": 0.9756826559702555, "text": "TNR"}, {"box": [[593, 143], [613, 140], [616, 157], [596, 161]], "score": 0.923158605893453, "text": "0.8"}, {"box": [[874, 142], [893, 142], [893, 160], [874, 160]], "score": 0.9974882205327352, "text": "0.8"}, {"box": [[383, 140], [395, 152], [384, 163], [373, 151]], "score": 0.3273014426231384, "text": "0"}, {"box": [[594, 166], [614, 166], [614, 184], [594, 184]], "score": 0.8939788341522217, "text": "0.7"}, {"box": [[874, 166], [892, 166], [892, 184], [874, 184]], "score": 0.998417059580485, "text": "0.7"}, {"box": [[315, 207], [335, 207], [335, 223], [315, 223]], "score": 0.9767971833546957, "text": "0.6"}, {"box": [[595, 211], [615, 211], [615, 229], [595, 229]], "score": 0.9973602692286173, "text": "0.5"}, {"box": [[655, 212], [670, 212], [670, 226], [655, 226]], "score": 0.9899243513743082, "text": "0.5"}, {"box": [[874, 211], [892, 211], [892, 230], [874, 230]], "score": 0.9963547786076864, "text": "0.5"}, {"box": [[242, 222], [287, 222], [287, 236], [242, 236]], "score": 0.9242334067821503, "text": "Model acci"}, {"box": [[522, 222], [576, 222], [576, 236], [522, 236]], "score": 0.9502861897150675, "text": "Model accura"}, {"box": [[797, 220], [866, 223], [865, 237], [796, 235]], "score": 0.8766021877527237, "text": "Model accuracy"}, {"box": [[656, 237], [669, 237], [669, 249], [656, 249]], "score": 0.992861290772756, "text": "0.4"}, {"box": [[275, 243], [315, 243], [315, 260], [275, 260]], "score": 0.8581300675868988, "text": "\uff19 10"}, {"box": [[570, 244], [591, 244], [591, 259], [570, 259]], "score": 0.9877593815326691, "text": "10"}, {"box": [[498, 247], [509, 247], [509, 256], [498, 256]], "score": 0.9974583983421326, "text": "6"}, {"box": [[140, 248], [151, 248], [151, 256], [140, 256]], "score": 0.9892680048942566, "text": "2"}, {"box": [[169, 255], [259, 257], [259, 275], [169, 272]], "score": 0.9013238092263539, "text": "Privacy budget "}, {"box": [[447, 255], [539, 257], [539, 275], [447, 272]], "score": 0.9214551039040089, "text": "Privacy budget e"}, {"box": [[728, 255], [819, 257], [819, 275], [728, 272]], "score": 0.8947759656345143, "text": "Privacy bud get e"}, {"box": [[177, 285], [252, 285], [252, 305], [177, 305]], "score": 0.9750361859798431, "text": "(a) CelebA"}, {"box": [[727, 286], [821, 286], [821, 306], [727, 306]], "score": 0.9384876241286596, "text": "(c) CIFAR-10"}, {"box": [[449, 287], [540, 287], [540, 307], [449, 307]], "score": 0.9780709197123846, "text": "(b) ImageNet"}, {"box": [[64, 324], [926, 324], [926, 344], [64, 344]], "score": 0.9361608307640832, "text": "Figure 5: Attack success rate of AMI against an e-LDP mechanism on CelebA, ImageNet, and CIFAR-10 datasets. The"}, {"box": [[62, 344], [927, 345], [927, 365], [62, 364]], "score": 0.9258993759872468, "text": "success rate is represented via the advantage (Adv), true positive rate (TPR), and true negative rate (TNR) according to Eq"}, {"box": [[59, 364], [895, 360], [895, 387], [59, 391]], "score": 0.952511383027866, "text": " The baseline of random guessing is 0.5. The model accuracy illustrates the utility loss of the data when using LDP."}, {"box": [[458, 599], [526, 596], [526, 618], [458, 620]], "score": 0.8950805153165545, "text": "(b) = 7"}, {"box": [[756, 599], [824, 596], [825, 618], [757, 620]], "score": 0.8211741277149746, "text": "(c)\u03b5= 5"}, {"box": [[160, 598], [233, 598], [233, 619], [160, 619]], "score": 0.8834076166152954, "text": "(a) \u03b5 = 10"}, {"box": [[64, 634], [925, 634], [925, 655], [64, 655]], "score": 0.937099447975988, "text": "Figure 6: Visualizing the distribution of the target sample t among other samples in the training set D using t-SNE"}, {"box": [[63, 657], [926, 657], [926, 677], [63, 677]], "score": 0.9398318543907039, "text": "embeddings. The red dots denote the target sample t and a multitude of its LDP noises M(t, e), while the blue dots denote"}, {"box": [[63, 678], [658, 678], [658, 698], [63, 698]], "score": 0.9375408335429866, "text": "other non-target samples. These data samples are obtained from the CelebA dataset."}, {"box": [[64, 736], [482, 736], [482, 756], [64, 756]], "score": 0.9389591358209911, "text": "defend against our AMI attack. Across all three datasets,"}, {"box": [[508, 736], [925, 736], [925, 757], [508, 757]], "score": 0.9754441459973653, "text": "shows that the t-SNE algorithm is able to group together the"}, {"box": [[63, 758], [483, 758], [483, 777], [63, 777]], "score": 0.95205812950929, "text": "the model accuracy on the legitimate classification task re-"}, {"box": [[506, 758], [926, 757], [926, 777], [506, 778]], "score": 0.9472170958916346, "text": "target sample t and its randomized variants. This is because"}, {"box": [[508, 779], [925, 779], [925, 800], [508, 800]], "score": 0.9512018219188407, "text": "the LDP mechanism imposes a small amount of noise such"}, {"box": [[63, 780], [481, 780], [481, 800], [63, 800]], "score": 0.9567870061312403, "text": "mains acceptable given  \u2265 5. However, our attack imposes"}, {"box": [[62, 801], [480, 801], [480, 821], [62, 821]], "score": 0.9599955623800104, "text": "a severely high success rate (\u2265 0.77), which approaches"}, {"box": [[508, 801], [925, 801], [925, 820], [508, 820]], "score": 0.9119299752958889, "text": "that t and its randomized variants M(t, ) closely resemble"}, {"box": [[62, 822], [481, 822], [481, 843], [62, 843]], "score": 0.9095605520101694, "text": "a near perfect success rate of 0.99 with \u03b5 \u2265 9. When"}, {"box": [[506, 821], [928, 822], [928, 843], [506, 842]], "score": 0.9331919132617482, "text": " one another. Hence, t-SNE models these by nearby points."}, {"box": [[62, 843], [480, 843], [480, 863], [62, 863]], "score": 0.9134225072497029, "text": "we reduce the privacy budget (e E [3, 4]), our attack still"}, {"box": [[509, 843], [926, 843], [926, 862], [509, 862]], "score": 0.9356182904566749, "text": "Therefore, it is easy for our attack to train a neuron that"}, {"box": [[63, 864], [481, 864], [481, 884], [63, 884]], "score": 0.9603343693936457, "text": "maintains a success rate of at least 0.67, 0.58, and 0.62, on"}, {"box": [[508, 864], [926, 864], [926, 884], [508, 884]], "score": 0.9227015350834799, "text": "can distinguish M(t, e) from other samples, resulting in an"}, {"box": [[63, 884], [477, 885], [477, 905], [63, 904]], "score": 0.9389738028699701, "text": "CelebA, ImageNet, and CIFAR-10, respectively. With very"}, {"box": [[506, 882], [877, 885], [877, 908], [506, 905]], "score": 0.9692621196017546, "text": "attack success rate of about 0.99 as shown in Fig. "}, {"box": [[63, 906], [480, 906], [480, 927], [63, 927]], "score": 0.9518716921066416, "text": "low e (e  [1, 2]), the model accuracy is severely damaged."}, {"box": [[509, 916], [925, 916], [925, 937], [509, 937]], "score": 0.9039000535712522, "text": "At  = 5, Fig.  shows that M(t, e) blends into other"}, {"box": [[63, 936], [483, 936], [483, 959], [63, 959]], "score": 0.9574662812969141, "text": "Furthermore, Fig. Edepicts the TPR and TNR of our attack."}, {"box": [[507, 938], [925, 938], [925, 958], [507, 958]], "score": 0.9708401550680904, "text": "samples, meaning that t-SNE is unable to group together the"}, {"box": [[64, 959], [481, 959], [481, 979], [64, 979]], "score": 0.95624836249785, "text": "Recall that TPR denotes how well the attack detects the"}, {"box": [[507, 959], [926, 959], [926, 980], [507, 980]], "score": 0.9499220334250351, "text": "randomized variants of t as in the previous Fig. a This is"}, {"box": [[62, 981], [482, 979], [482, 999], [62, 1001]], "score": 0.9648946796433401, "text": "presence of the target sample t in the training data D, and"}, {"box": [[506, 979], [927, 980], [927, 1000], [506, 999]], "score": 0.9435223037341856, "text": "because the mechanism M(-, ) imposes a high amount of"}, {"box": [[62, 999], [481, 1000], [481, 1021], [62, 1020]], "score": 0.9191199023472635, "text": "TNR measures the ability to detect the absence of t. From"}, {"box": [[507, 1001], [926, 1001], [926, 1021], [507, 1021]], "score": 0.9236208010336449, "text": "noise at e = 5, so that all randomized variants M(t, e) no"}, {"box": [[63, 1023], [482, 1023], [482, 1043], [63, 1043]], "score": 0.9250569831708382, "text": "the result, we can see that our attack has high TPR across"}, {"box": [[508, 1023], [926, 1023], [926, 1043], [508, 1043]], "score": 0.9358002897036277, "text": "longer closely resemble one another. This makes the task of"}, {"box": [[63, 1044], [481, 1044], [481, 1063], [63, 1063]], "score": 0.9285550572104373, "text": "all scenarios, which means it is sensitive to detecting the"}, {"box": [[509, 1044], [925, 1044], [925, 1063], [509, 1063]], "score": 0.889354821768674, "text": "finding the decision boundary between M(t, e) and other"}, {"box": [[63, 1066], [481, 1066], [481, 1085], [63, 1085]], "score": 0.9029630926522342, "text": "case where t E D. Moreover, our TNR is greater than 0.5"}, {"box": [[508, 1066], [926, 1066], [926, 1085], [508, 1085]], "score": 0.9592013667736735, "text": "samples more difficult. Nevertheless, our AMI attack can"}, {"box": [[63, 1086], [481, 1086], [481, 1105], [63, 1105]], "score": 0.9582857151152724, "text": "indicating the capability of discerning the absence of t in"}, {"box": [[507, 1085], [802, 1085], [802, 1108], [507, 1108]], "score": 0.9516636504067315, "text": "still attain a success rate of 0.80 (Fig. E)."}, {"box": [[63, 1107], [481, 1107], [481, 1127], [63, 1127]], "score": 0.9615025593609107, "text": "the training data (except for the ImageNet dataset at e \u2264 4)."}, {"box": [[509, 1130], [925, 1130], [925, 1149], [509, 1149]], "score": 0.9423473360491734, "text": "Certified Guarantee of Success. Given a privacy bud"}, {"box": [[65, 1151], [481, 1151], [481, 1172], [65, 1172]], "score": 0.9255627071857453, "text": "Training the Chosen Neuron under LDP. Training the"}, {"box": [[507, 1150], [928, 1149], [928, 1173], [507, 1174]], "score": 0.9190993968929563, "text": "get  E [1, 10], in order to check the certified guanran-"}, {"box": [[62, 1173], [482, 1172], [482, 1192], [62, 1193]], "score": 0.9487667401631673, "text": "chosen neuron is equivalent to determining a decision bound-"}, {"box": [[508, 1173], [923, 1173], [923, 1192], [508, 1192]], "score": 0.9545398475947203, "text": "tee conditions as in Theorem , we obtain the the lower"}, {"box": [[506, 1189], [924, 1190], [924, 1217], [506, 1216]], "score": 0.8225181684471093, "text": "and upper bounds Eb [v(t)] and iEub [v()] (Eqs. and "}, {"box": [[64, 1194], [482, 1194], [482, 1215], [64, 1215]], "score": 0.9441716847783428, "text": "ary that can distinguish the target sample (and its random-"}, {"box": [[63, 1214], [482, 1214], [482, 1237], [63, 1237]], "score": 0.9527585501300877, "text": "ized variants) from any other samples. Fig. visualizes how"}, {"box": [[508, 1215], [925, 1215], [925, 1235], [508, 1235]], "score": 0.9100554119456898, "text": "by using 4, 000 s-LDP target samples M(t, e) and all s-"}, {"box": [[62, 1235], [481, 1234], [481, 1255], [62, 1256]], "score": 0.9370149940740867, "text": "the samples in the training set D are distributed using t-SNE"}, {"box": [[508, 1234], [927, 1234], [927, 1258], [508, 1258]], "score": 0.9274552150776512, "text": "LDP non-target samples M(r, e) from the validation set of"}, {"box": [[64, 1258], [460, 1258], [460, 1278], [64, 1278]], "score": 0.8933907510066519, "text": "[Van der Maaten and Hinton, 2008]. At  = 10, Fig."}, {"box": [[456, 1259], [482, 1259], [482, 1278], [456, 1278]], "score": 0.592643529176712, "text": "ba"}, {"box": [[508, 1258], [926, 1258], [926, 1277], [508, 1277]], "score": 0.9312507674098015, "text": "each dataset. Here we use BitRand [Lai et al., 2021]] as the"}]}